{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df1ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac6ea23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "CUDA is NOT available. Check your driver or setup.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is NOT available. Check your driver or setup.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "675f2beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7935fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu118\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"‚ùå CUDA is NOT available. Likely driver or install issue.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3762676",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dest = \"inaturalist_12K/train/Amphibia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "891b22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = listdir(images_dest)\n",
    "data = []\n",
    "#extracting the images from the folder\n",
    "for image in images:\n",
    "    if isfile(join(images_dest, image)):\n",
    "        # print(image)\n",
    "        #resizing the image to 224x224\n",
    "        img = cv2.imread(join(images_dest, image))\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14269d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc195b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],   # ImageNet mean\n",
    "                         [0.229, 0.224, 0.225])   # ImageNet std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fd39b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# === CONFIG ===\n",
    "data_dir = \"./inaturalist_12K\"  # Your dataset directory (train & val inside this)\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# === TRANSFORMS ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],   # ImageNet mean\n",
    "                         [0.229, 0.224, 0.225])   # ImageNet std\n",
    "])\n",
    "\n",
    "# === DATASET LOADING ===\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, \"val\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# === LOAD GOOGLENET & MODIFY ===\n",
    "model = models.googlenet(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace only the final classifier layer\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Enable training only on the new final layer\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# === LOSS & OPTIMIZER ===\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f717b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRAIN LOOP ===\n",
    "def train_model():\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "        evaluate_accuracy(model, val_loader, device)\n",
    "\n",
    "# === EVALUATE ===\n",
    "def evaluate_accuracy(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "# === START TRAINING ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29d0c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.3835\n",
      "Validation Accuracy: 68.90%\n",
      "Epoch [2/5], Loss: 0.9639\n",
      "Validation Accuracy: 69.30%\n",
      "Epoch [3/5], Loss: 0.8861\n",
      "Validation Accuracy: 69.90%\n",
      "Epoch [4/5], Loss: 0.8409\n",
      "Validation Accuracy: 70.60%\n",
      "Epoch [5/5], Loss: 0.8089\n",
      "Validation Accuracy: 70.75%\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca7c473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 74.24%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.23742374237423"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(model, train_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
